model:
  base_learning_rate: 5e-5
  target: cfm.models.diffusion.cfm_scale_cfg.CFM_MAA2_CFG
  params:
    linear_start: 0.00085
    linear_end: 0.0120
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    mel_dim: 20
    mel_length: 256
    first_stage_key: "mix_spec"
    cond_stage_key: "mix_video_feat"
    image_size: 64
    channels: 0 
    cond_stage_trainable: true   
    conditioning_key: crossattn
    monitor: val/loss_simple_ema
    scale_factor: 0.18215
    use_ema: False

    scheduler_config:
      target: cfm.lr_scheduler.LambdaLinearScheduler
      params:
        warm_up_steps: [ 1000 ]
        cycle_lengths: [ 10000000000000 ] 
        f_start: [ 1.e-6 ]
        f_max: [ 1. ]
        f_min: [ 1. ]

    unet_config:
      target: cfm.modules.diffusionmodules.concatDiT.ChannelConcatDiT
      params:
        in_channels: 20
        context_dim: 768
        hidden_size: 576
        num_heads: 8
        depth: 4
        max_len: 1000

    first_stage_config:
      target: cfm.models.autoencoder1d.AutoencoderKL
      params:
        embed_dim: 20
        monitor: val/rec_loss
        ckpt_path: ckpt/trainae/ckpt/epoch=000032.ckpt
        ddconfig:
          double_z: true
          in_channels: 80
          out_ch: 80
          z_channels: 20
          kernel_size: 5
          ch: 384
          ch_mult:
          - 1
          - 2
          - 4
          num_res_blocks: 2
          attn_layers:
          - 3
          down_layers:
          - 0
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity
    
    cond_stage_config: 
      target: cfm.modules.cond_stage.video_feat_encoder.Video_Feat_Encoder_NoPosembed
      params:
        origin_dim: 512
        embed_dim: 768
        seq_len: 40




